{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sam\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "sigma=1\n",
    "lenInput=5000\n",
    "u= np.array([int(random.choice([False, True])) for i in range(lenInput)])\n",
    "u= u*2 -1\n",
    "M= 9 #amount of delay (number of features)\n",
    "count=0\n",
    "u=u[:,None]\n",
    "\n",
    "for iterations in range (0,10):\n",
    "\n",
    "    x=np.array([u[i]+0.5*u[i-1] if i>0 else 0 for i in range(lenInput)])\n",
    "    y=np.array([ x[i]- 0.9*pow(x[i],3) for i in range(lenInput)])\n",
    "    noise=np.random.normal(0, sigma, lenInput)\n",
    "    output= y+noise\n",
    "\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    X_train, X_test, y_train, y_test=train_test_split(output,u, test_size=0.4)\n",
    "    \n",
    "    \n",
    "    XTrain_features=np.array([X_train[i-M+1:i+1] for i in range(M-1,len(X_train))])\n",
    "    XTest_features=np.array([X_test[i-M+1:i+1] for i in range(M-1,len(X_test))])\n",
    "    \n",
    "    y_train=y_train.ravel();\n",
    "    y_test=y_test.ravel();\n",
    "    \n",
    "    \n",
    "    #y_train= y_train[:,None]\n",
    "    clfsvm = svm.SVC()\n",
    "    clfsvm.fit(XTrain_features, y_train[M-1:])\n",
    "    '''\n",
    "    clfADAforest = AdaBoostRegressor(RandomForestRegressor(max_depth=2))\n",
    "    clfADAdt = AdaBoostRegressor(tree.DecisionTreeRegressor(max_depth=2))\n",
    "    clf=RandomForestRegressor(max_depth=2)\n",
    "    clfdt=tree.DecisionTreeRegressor(max_depth=2)\n",
    "    '''\n",
    "    \n",
    "    clfADAforest = AdaBoostClassifier(RandomForestClassifier())\n",
    "    clfADAdt = AdaBoostClassifier(tree.DecisionTreeClassifier())\n",
    "    \n",
    "    clfGB = GradientBoostingClassifier()\n",
    "    \n",
    "    clf=RandomForestClassifier()\n",
    "    clfdt=tree.DecisionTreeClassifier()\n",
    "    clflogistic = linear_model.LogisticRegression()\n",
    "    clfDTbagging = BaggingClassifier(base_estimator=tree.DecisionTreeClassifier())\n",
    "    \n",
    "    clf.fit(XTrain_features, y_train[M-1:])\n",
    "    clfADAforest.fit(XTrain_features, y_train[M-1:])\n",
    "    clfADAdt.fit(XTrain_features, y_train[M-1:])\n",
    "    clfGB.fit(XTrain_features, y_train[M-1:])\n",
    "    clfdt.fit(XTrain_features, y_train[M-1:])\n",
    "    clflogistic.fit(XTrain_features, y_train[M-1:])\n",
    "    clfDTbagging.fit(XTrain_features, y_train[M-1:])\n",
    "    test_check=y_test[M-1:];\n",
    "    test_check_size= len(test_check)\n",
    "    \n",
    "    pp= clfsvm.predict(XTest_features)\n",
    "    #print(\"SVM Score: \",sum(test_check==pp)/test_check_size)\n",
    "    SVMresult=sum(test_check==pp)/test_check_size\n",
    "    pp=clfdt.predict(XTest_features)\n",
    "    #print(\"Decision Tree Score: \",sum(test_check==pp)/test_check_size)\n",
    "    \n",
    "    pp=clf.predict(XTest_features)\n",
    "    #print(\"Random Forest Score: \",sum(test_check==pp)/test_check_size)\n",
    "    \n",
    "    pp=clfADAdt.predict(XTest_features)\n",
    "    #print(\"ADA Boosted Decision Tree Score: \",sum(test_check==pp)/test_check_size)\n",
    "    \n",
    "    pp=clfADAforest.predict(XTest_features)\n",
    "    #print(\"ADA Boosted Random Forest Score: \",sum(test_check==pp)/test_check_size)\n",
    "    \n",
    "    pp=clfGB.predict(XTest_features)\n",
    "    #print(\"Gradient Boosted Decision Tree Score: \",\n",
    "    GBresult=sum(test_check==pp)/test_check_size\n",
    "    \n",
    "    pp=clflogistic.predict(XTest_features)\n",
    "    #print(\"Logistic Regression Score: \",sum(test_check==pp)/test_check_size)\n",
    "    \n",
    "    pp=clfDTbagging.predict(XTest_features)\n",
    "    #print(\"Bagged Decision Tree Score: \",sum(test_check==pp)/test_check_size)\n",
    "    if(SVMresult<GBresult):\n",
    "        count=count+1;\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
